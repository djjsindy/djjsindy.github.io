<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>djjsindy</title><link href="/" rel="alternate"></link><link href="/feeds/socket.atom.xml" rel="self"></link><id>/</id><updated>2014-06-20T15:28:00+02:00</updated><entry><title>ip分段重组流程</title><link href="/ipfen-duan-zhong-zu-liu-cheng.html" rel="alternate"></link><updated>2014-06-20T15:28:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-06-20:ipfen-duan-zhong-zu-liu-cheng.html</id><summary type="html">&lt;h1&gt;ip分段重组流程&lt;/h1&gt;
&lt;p&gt;数据链路层会限制发送网络帧的长度(mtu)，这样如果网络层发送的报文长度如果超过了mtu，那么ip协议会将发送的报文进行拆分分段。&lt;/p&gt;
&lt;p&gt;ip协议报文结构&lt;/p&gt;
&lt;p&gt;&lt;img src="http://i1166.photobucket.com/albums/q601/djjsindy/my%20blog/ScreenShot2014-06-18at30145PM_zpsb61308ae.png" width="300"&gt;&lt;/p&gt;
&lt;p&gt;ip协议中主要控制分段的部分是&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;16位标识符，同一个ip报文的多个分段具有相同的16位标识，网络层会根据这个标识来找到其他的已经收到的分段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3位标志，第一位暂时不用；第二位表示是否开启分段，1表示开启分段，0表示没有分段；第三位表示开启分段，是否到了分段的最后的一个分段，0表示到了最后一个分段，1表示还有其他的分段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;13位片内偏移，ip分段的位移以8字节作为单位，真实偏移字节数是13位片内位移＊8&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ip协议有这么几个特点，数据报可能会丢失、重复传输、延迟、乱序，针对分段重组需要解决这几个问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分段之间的重叠问题，如何解决？&lt;/li&gt;
&lt;li&gt;如果某一个ip报文中的某个分段丢失，长时间收不到这个分段，相关结构如何回收，如果不回收肯定会撑爆内存？&lt;/li&gt;
&lt;li&gt;所有分组的分配的内存都有一个限制，如果内存分配达到阈值，如何回收相关的结构？&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;分段初始化&lt;/h3&gt;
&lt;p&gt;内核用struct inet_frag_queue来记录同一ip报文的多个分组&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
struct inet_frag_queue {
    struct hlist_node   list;
    struct netns_frags  *net; 
    //当这个ip报文重组完成之后，就把当前结构体加入到回收链表中，方便当内存紧张的时候，达到阈值的时候回收lru_list中的inet_frag_queue
    struct list_head    lru_list;   /* lru list member */
    spinlock_t      lock;
    atomic_t        refcnt;
    //当分段超时的时候，timer用于回收内存
    struct timer_list   timer;      /* when will this queue expire? */
    //记录sk_buff链表，每一个sk_buff是分段链表
    struct sk_buff      *fragments; /* list of received fragments */
    //记录分段链表的尾，这个字段是为了加速确定分段的位置，每个分段用offset跟tail比较，若比tail小，那么需要递归确定新分段的位置；如果比tail大，那么就不需要递归了
    struct sk_buff      *fragments_tail;
    ktime_t         stamp;
    //记录当前接受分组最大的结束的位置
    int         len;        /* total length of orig datagram */
    //记录分组一共接受的数据字节数，当meat＝len的时候表示所有得分段都接受完毕了
    int         meat;
    __u8            last_in;    /* first/last segment arrived? */

#define INET_FRAG_COMPLETE  4 //表示分段都接收完毕
#define INET_FRAG_FIRST_IN  2 //表示接收一个位置分段
#define INET_FRAG_LAST_IN   1 //表示接收最后一个位置的分段
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;inet_frag_queue表示同一个ip报文的多个分段，这个结构被存在一个hash表中，根据id，源ip，目的ip，传输层协议号来作为key，能够快速的找到这个inet_frag_queue，如果没有找到这个结构，就会初始化一个inet_frag_queue。&lt;/p&gt;
&lt;p&gt;系统启动时的分段初始化函数，ip4_frags参数是一个全局配置参数。
&lt;pre&gt;&lt;code&gt;
void __init ipfrag_init(void)
{
    ip4_frags_ctl_register();
    register_pernet_subsys(&amp;amp;ip4_frags_ops);
    ip4_frags.hashfn = ip4_hashfn;  //存储inet_frag_queue的hash结构
    ip4_frags.constructor = ip4_frag_init; //每一个inet_frag_queue初始化函数，当当前分段在hash中找不到结构，那么就需要调用这个回调函数
    ip4_frags.destructor = ip4_frag_free; //当内存分配达到上限的时候，就调用这个回调函数，回收inet_frag_queue
    ip4_frags.skb_free = NULL;
    ip4_frags.qsize = sizeof(struct ipq);//每次分配inet_frag_queue结构的时候，每个结构体的大小就是每次分配的内存大小
    ip4_frags.match = ip4_frag_match;
    ip4_frags.frag_expire = ip_expire; //当一个ip报文的某个分组在一段时间内未接收完全，就抛弃这个ip报文
    ip4_frags.secret_interval = 10 * 60 * HZ;//在根据ip报文计算inet_frag_queue hash值需要一个secret，这个secret是一直在变化的，这个参数是变化的间隔
    inet_frags_init(&amp;amp;ip4_frags);
}
&lt;/code&gt;&lt;/pre&gt;
ip4_frags_ops的初始化函数
&lt;pre&gt;&lt;code&gt;
static int __net_init ipv4_frags_init_net(struct net *net)
{  &lt;br /&gt;
    net-&amp;gt;ipv4.frags.high_thresh = 256 * 1024; //内存上限，当超过这个数值的时候开始回收inet_frag_queue
    net-&amp;gt;ipv4.frags.low_thresh = 192 * 1024; //回收内存尽可能的回收到这个数值之下
    net-&amp;gt;ipv4.frags.timeout = IP_FRAG_TIME; //30HZ,一个ip报文收集全所有分段的过期时间，如果超过这段时间，就会回收分配的inet_frag_queue结构
    inet_frags_init_net(&amp;amp;net-&amp;gt;ipv4.frags);
    return ip4_frags_ns_ctl_register(net);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h3&gt;分段重组&lt;/h3&gt;
&lt;p&gt;linux内核在网路层向传输层提交数据之前会检查接收到的ip报文，检查3位标志位和后面的13位偏移。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
//frag_off是3位标志位和13位片内偏移总和，如果不是最后一个分片或者有片偏移就进行重组分段
if (ip_hdr(skb)-&gt;frag_off &amp; htons(IP_MF | IP_OFFSET)) {
        if (ip_defrag(skb, IP_DEFRAG_LOCAL_DELIVER))
            return 0;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ip_defrag的流程是从ip4_frags的hash表中查询是否有相关的inet_frag_queue结构，如果有就返回，把当前的sk_buff加入到inet_frag_queue中，如果找不到就创建一个inet_frag_queue，插入到hash表中。后面最重要的过程就是重组ip报文，所有的步骤集中在了ip_frag_queue函数中。这个函数过程分为这几步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从当前分段中确定当前sk_buff的offset和end。&lt;/li&gt;
&lt;li&gt;根据offset确定在当前sk_buff在inet_frag_queue中的位置。&lt;/li&gt;
&lt;li&gt;处理当前sk_buff和prev sk_buff重叠的数据的情况&lt;/li&gt;
&lt;li&gt;处理当前sk_buff和next sk_buff重叠的数据的情况&lt;/li&gt;
&lt;li&gt;把当前sk_buff加入到inet_frag_queue中的链表中，更新相关数据&lt;/li&gt;
&lt;li&gt;判断如果当前ip报文的所有分组都接收完毕，调用ip_frag_reasm函数重新装填ip报文&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;在处理重叠的时候，默认重叠部分都是优先采用offset靠前sk_buff中的数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面分布说明重组过程&lt;/p&gt;
&lt;h6&gt;1.从当前分段中确定当前sk_buff的offset和end&lt;/h6&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;
    ecn = ip4_frag_ecn(ip_hdr(skb)-&amp;gt;tos); 
    offset = ntohs(ip_hdr(skb)-&amp;gt;frag_off); //16位包括3位标志位，13位片内偏移
    flags = offset &amp;amp; ~IP_OFFSET; //获得3位标志位
    offset &amp;amp;= IP_OFFSET; //13位片内偏移
    offset &amp;lt;&amp;lt;= 3;       /&lt;em&gt; offset is in 8-byte chunks &lt;/em&gt;///13位片内偏移，这个表示按照8位为一个偏移，所以要乘以8
    ihl = ip_hdrlen(skb);
    //按照offset和sk_buff的len，计算出这个报文中数据的结束的位置，len表示从头部开始到最后的数据结束长度，所以计算数据的结束的位置，要减去头部的长度ihl
    end = offset + skb-&amp;gt;len - ihl;
    err = -EINVAL;
    //更新q.len，表示接收分段的最大的结束的位置。
    /&lt;em&gt; Is this the final fragment? &lt;/em&gt;/
    if ((flags &amp;amp; IP_MF) == 0) {
        /&lt;em&gt; If we already have some bits beyond end
         * or have different end, the segment is corrrupted.
         &lt;/em&gt;/
        if (end &amp;lt; qp-&amp;gt;q.len ||
            ((qp-&amp;gt;q.last_in &amp;amp; INET_FRAG_LAST_IN) &amp;amp;&amp;amp; end != qp-&amp;gt;q.len))
            goto err;
        qp-&amp;gt;q.last_in |= INET_FRAG_LAST_IN;
        qp-&amp;gt;q.len = end;
    } else {
        if (end&amp;amp;7) {
            end &amp;amp;= ~7;
            if (skb-&amp;gt;ip_summed != CHECKSUM_UNNECESSARY)
                skb-&amp;gt;ip_summed = CHECKSUM_NONE;
        }
        if (end &amp;gt; qp-&amp;gt;q.len) {
            /&lt;em&gt; Some bits beyond end -&amp;gt; corruption. &lt;/em&gt;/
            if (qp-&amp;gt;q.last_in &amp;amp; INET_FRAG_LAST_IN)
                goto err;
            qp-&amp;gt;q.len = end;
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h6&gt;2.根据offset确定在当前sk_buff在inet_frag_queue中的位置&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;
    //首先从结尾开始尝试比较sk_buff的位置，如果大于prev，就证明sk_buff在结尾的后面，就不用递归确定位置了
    prev = qp-&gt;q.fragments_tail;
    if (!prev || FRAG_CB(prev)-&gt;offset &lt; offset) {
        next = NULL;
        goto found;
    }
    //从开始开始递归比较offset，确定位置，
    prev = NULL;
    for (next = qp-&gt;q.fragments; next != NULL; next = next-&gt;next) {
        if (FRAG_CB(next)-&gt;offset &gt;= offset)
            break;  /* bingo! */
        prev = next;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样已经确定出当前sk_buff在inet_frag_queue位置，有了prev和next指针，可能这两个指针都是空&lt;/p&gt;
&lt;h6&gt;3.处理当前sk_buff和prev sk_buff重叠的数据的情况&lt;/h6&gt;
&lt;p&gt;我们唯一可以确定的事情就是current和prev直接offset的关系，是prev&amp;lt;=current，但是结尾的位置关系不确定。
&lt;img src="http://i1166.photobucket.com/albums/q601/djjsindy/my%20blog/ScreenShot2014-06-19at113152AM_zps79bf0c7b.png" width="300"&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看出前两种情况都是ok的，第三种情况出现了重叠情况，这样会把重叠部分从current中去掉，这样重叠部分取自prev分段。&lt;/p&gt;
&lt;p&gt;这里重叠部分不会更新meat，因为current的增加的数据量在第5步有更新。prev的数据量没有变化
&lt;pre&gt;&lt;code&gt;
if (prev) {
        //计算重叠部分即prev-&amp;gt;end-current-&amp;gt;offset
        int i = (FRAG_CB(prev)-&amp;gt;offset + prev-&amp;gt;len) - offset;
        if (i &amp;gt; 0) {
            //更新当前的offset＋i，即忽略掉current重叠的部分
            offset += i;
            err = -EINVAL;
            if (end &amp;lt;= offset)
                goto err;
            err = -ENOMEM;
            if (!pskb_pull(skb, i))
                goto err;
            if (skb-&amp;gt;ip_summed != CHECKSUM_UNNECESSARY)
                skb-&amp;gt;ip_summed = CHECKSUM_NONE;
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h6&gt;4.处理当前sk_buff和next sk_buff重叠的数据的情况&lt;/h6&gt;
&lt;p&gt;&lt;img src="http://i1166.photobucket.com/albums/q601/djjsindy/my%20blog/ScreenShot2014-06-19at115541AM_zpsbd2e8f5d.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;从上图中可以看出前两种情况都是ok得，后面两种都是需要处理得重叠情况，第三种需要把next去掉重叠部分，然后meat减少重叠得长度，第四种情况是完全重叠得情况，由于重叠部分优先使用offset考前的sk_buff,所以这种情况下去掉next就可以了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
while (next &amp;&amp; FRAG_CB(next)-&gt;offset &lt; end) {
        //计算重叠的长度
        int i = end - FRAG_CB(next)-&gt;offset; /* overlap is 'i' bytes */
        //第三种情况，表示部分重叠，可以知道next的next如果有的话，肯定不和current重叠，所以最后break
        if (i &lt; next-&gt;len) {
            /* Eat head of the next overlapped fragment
             * and leave the loop. The next ones cannot overlap.
             */
             //折叠next
            if (!pskb_pull(next, i))
                goto err;
            //更新next的offset，使offset到达current的结束边缘
            FRAG_CB(next)-&gt;offset += i;
            //更新实际接收数据量，因为重叠部分被处理掉了
            qp-&gt;q.meat -= i;
            if (next-&gt;ip_summed != CHECKSUM_UNNECESSARY)
                next-&gt;ip_summed = CHECKSUM_NONE;
            break;
        } else {
            //完全重叠的情况，只需要从链表中去掉next
            struct sk_buff *free_it = next;

            /* Old fragment is completely overridden with
             * new one drop it.
             */
            next = next-&gt;next;
            //去掉next
            if (prev)
                prev-&gt;next = next;
            else
                qp-&gt;q.fragments = next;
            //减少next的数据量
            qp-&gt;q.meat -= free_it-&gt;len;
            frag_kfree_skb(qp-&gt;q.net, free_it);
        }
    }

&lt;/code&gt;&lt;/pre&gt;

&lt;h6&gt;5.把当前sk_buff加入到inet_frag_queue中的链表中，更新相关数据&lt;/h6&gt;
&lt;p&gt;重叠sk_buff处理完毕了，紧接着就该把current加入到inet_frag_queue的链表中了，同时更新meat，更新mem大小，以便mem超过了high_thresh，回收数据。
&lt;pre&gt;&lt;code&gt;
    FRAG_CB(skb)-&amp;gt;offset = offset;
    /&lt;em&gt; Insert this fragment in the chain of fragments. &lt;/em&gt;/
    //插入链表
    skb-&amp;gt;next = next;
    if (!next)
        qp-&amp;gt;q.fragments_tail = skb;
    if (prev)
        prev-&amp;gt;next = skb;
    else
        qp-&amp;gt;q.fragments = skb;
    dev = skb-&amp;gt;dev;
    if (dev) {
        qp-&amp;gt;iif = dev-&amp;gt;ifindex;
        skb-&amp;gt;dev = NULL;
    }
    //更新meat，mem
    qp-&amp;gt;q.stamp = skb-&amp;gt;tstamp;
    qp-&amp;gt;q.meat += skb-&amp;gt;len;
    qp-&amp;gt;ecn |= ecn;
    atomic_add(skb-&amp;gt;truesize, &amp;amp;qp-&amp;gt;q.net-&amp;gt;mem);
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h6&gt;6.判断如果当前ip报文的所有分组都接收完毕，调用ip_frag_reasm函数重新装填ip报文&lt;/h6&gt;
&lt;p&gt;判断ip报文所有分段接收完毕根据meat是否等于len,如果等于len，那么调用ip_frag_reasm函数，认为当前sk_buff是报文的第一个分组，把当前sk_buff赋予inet_frag_queue的第一个sk_buff，同时把其他分组放到sk_buff的frag_list中，同时更新sk_buff的其他参数
&lt;pre&gt;&lt;code&gt;
//head就是本次接收的sk_buff，如果有prev，就是说当前sk_buff不是第一个位置的分段，需要让它变成第一个位置的分段
if (prev) {
        head = prev-&amp;gt;next;
        //fp是一个替代current的sk_buff
        fp = skb_clone(head, GFP_ATOMIC);
        if (!fp)
            goto out_nomem;
        //head的位置让fp替代
        fp-&amp;gt;next = head-&amp;gt;next;
        if (!fp-&amp;gt;next)
            qp-&amp;gt;q.fragments_tail = fp;
        prev-&amp;gt;next = fp;
        //把head变成第一个分段
        skb_morph(head, qp-&amp;gt;q.fragments);
        head-&amp;gt;next = qp-&amp;gt;q.fragments-&amp;gt;next;
        kfree_skb(qp-&amp;gt;q.fragments);
        qp-&amp;gt;q.fragments = head;
    }
&lt;/code&gt;&lt;/pre&gt;
后面更新sk_buff的相关参数
&lt;pre&gt;&lt;code&gt;
    //把分段放入到frag_list中
    skb_shinfo(head)-&amp;gt;frag_list = head-&amp;gt;next;
    skb_push(head, head-&amp;gt;data - skb_network_header(head));
    //积累相关参数
    for (fp=head-&amp;gt;next; fp; fp = fp-&amp;gt;next) {
        head-&amp;gt;data_len += fp-&amp;gt;len;
        head-&amp;gt;len += fp-&amp;gt;len;
        if (head-&amp;gt;ip_summed != fp-&amp;gt;ip_summed)
            head-&amp;gt;ip_summed = CHECKSUM_NONE;
        else if (head-&amp;gt;ip_summed == CHECKSUM_COMPLETE)
            head-&amp;gt;csum = csum_add(head-&amp;gt;csum, fp-&amp;gt;csum);
        head-&amp;gt;truesize += fp-&amp;gt;truesize;
    }
    atomic_sub(head-&amp;gt;truesize, &amp;amp;qp-&amp;gt;q.net-&amp;gt;mem);
    head-&amp;gt;next = NULL;
    head-&amp;gt;dev = dev;
    head-&amp;gt;tstamp = qp-&amp;gt;q.stamp;
    iph = ip_hdr(head);
    iph-&amp;gt;frag_off = 0;
    iph-&amp;gt;tot_len = htons(len);
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h3&gt;分段定时器&lt;/h3&gt;
&lt;p&gt;每个ip分段都会设置一个定时器，防止长时间分段接收不完全，占用内存结构。
&lt;pre&gt;&lt;code&gt;
static void ip_expire(unsigned long arg)
{
    struct ipq &lt;em&gt;qp;
    struct net &lt;/em&gt;net;
    qp = container_of((struct inet_frag_queue &lt;em&gt;) arg, struct ipq, q);
    net = container_of(qp-&amp;gt;q.net, struct net, ipv4.frags);
    spin_lock(&amp;amp;qp-&amp;gt;q.lock);
    //如果接收完全了，就必要回收了
    if (qp-&amp;gt;q.last_in &amp;amp; INET_FRAG_COMPLETE)
        goto out;
    //更新引用计数，删除timer，从lru链表中删除qp
    ipq_kill(qp);
    IP_INC_STATS_BH(net, IPSTATS_MIB_REASMTIMEOUT);
    IP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);
    //如果接收第一个分段
    if ((qp-&amp;gt;q.last_in &amp;amp; INET_FRAG_FIRST_IN) &amp;amp;&amp;amp; qp-&amp;gt;q.fragments != NULL) {
        struct sk_buff &lt;/em&gt;head = qp-&amp;gt;q.fragments;
        const struct iphdr &lt;em&gt;iph;
        int err;
        rcu_read_lock();
        head-&amp;gt;dev = dev_get_by_index_rcu(net, qp-&amp;gt;iif);
        if (!head-&amp;gt;dev)
            goto out_rcu_unlock;
        /&lt;/em&gt; skb dst is stale, drop it, and perform route lookup again */
        skb_dst_drop(head);
        iph = ip_hdr(head);
        err = ip_route_input_noref(head, iph-&amp;gt;daddr, iph-&amp;gt;saddr,
                       iph-&amp;gt;tos, head-&amp;gt;dev);
        if (err)
            goto out_rcu_unlock;
        if (qp-&amp;gt;user == IP_DEFRAG_CONNTRACK_IN &amp;amp;&amp;amp;
            skb_rtable(head)-&amp;gt;rt_type != RTN_LOCAL)
            goto out_rcu_unlock;
        //发送icmp告诉对端，分段超时了
        icmp_send(head, ICMP_TIME_EXCEEDED, ICMP_EXC_FRAGTIME, 0);
out_rcu_unlock:
        rcu_read_unlock();
    }
out:
    spin_unlock(&amp;amp;qp-&amp;gt;q.lock);
    //释放分段中的结构
    ipq_put(qp);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;h3&gt;内存回收&lt;/h3&gt;
&lt;p&gt;在接收分段的过程中，ipv4.frags.mem表示分段未接收完全，分段占用的内存空间，在某个ip报文接收过程中，接收到了一个分段会增加相应的数据量，当这个报文分段接收完全后，会减少这个相应数据量，每次接收到新的分段的时候，都要检查这个mem，如果它高于high_thresh，就会开始回收，会牺牲一些未接收完全的inet_frag_queue，直到mem达到low_thresh。netns_frags里面的lru_list，就是记录还未接收完全分段的inet_frag_queue。当接收分段的时候，会把当前inet_frag_queue，移动到lru_list的结尾，回收inet_frag_queue的时候是从lru_list的头部开始回收。回收的函数是inet_frag_evictor
&lt;pre&gt;&lt;code&gt;
int inet_frag_evictor(struct netns_frags &lt;em&gt;nf, struct inet_frags &lt;/em&gt;f)
{
    struct inet_frag_queue *q;
    int work, evicted = 0;
    //计算出需要回收的数据量
    work = atomic_read(&amp;amp;nf-&amp;gt;mem) - nf-&amp;gt;low_thresh;
    while (work &amp;gt; 0) {
        read_lock(&amp;amp;f-&amp;gt;lock);
        if (list_empty(&amp;amp;nf-&amp;gt;lru_list)) {
            read_unlock(&amp;amp;f-&amp;gt;lock);
            break;
        }
        //从lru_list中取出inet_frag_queue
        q = list_first_entry(&amp;amp;nf-&amp;gt;lru_list,
                struct inet_frag_queue, lru_list);
        atomic_inc(&amp;amp;q-&amp;gt;refcnt);
        read_unlock(&amp;amp;f-&amp;gt;lock);
        spin_lock(&amp;amp;q-&amp;gt;lock);
        //如果分段没有接收完全，证明q还在lru_list中
        if (!(q-&amp;gt;last_in &amp;amp; INET_FRAG_COMPLETE))
            inet_frag_kill(q, f);
        spin_unlock(&amp;amp;q-&amp;gt;lock);
        //回收inet_frag_queue，更新work
        if (atomic_dec_and_test(&amp;amp;q-&amp;gt;refcnt))
            inet_frag_destroy(q, f, &amp;amp;work);
        evicted++;
    }
    return evicted;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;</summary><category term="socket"></category></entry><entry><title>epoll函数原理分析</title><link href="/epollhan-shu-yuan-li-fen-xi.html" rel="alternate"></link><updated>2014-05-20T14:51:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-05-20:epollhan-shu-yuan-li-fen-xi.html</id><summary type="html">&lt;h1&gt;epoll函数原理分析&lt;/h1&gt;
&lt;p&gt;select函数的在监控fd数量非常巨大的情况下，效率低，主要原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用户态下，每次调用select函数之前，需要把fd关注的事件重新设置，这样select函数到了内核态，需要频繁将用户态的数据复制到内核态。&lt;/li&gt;
&lt;li&gt;设备驱动在唤醒睡眠进程之后，需要重新扫描所有的fd，然后筛选fd产生的事件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;epoll函数之所以设计的高效是因为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;epoll函数需要创建自己单独的文件系统，返回给用户态epoll fd，这个fd是拿到内核态struct file的关键，找到了这个file，就能找到struct eventpoll全局结构体。每个用户态关注的事件，会直接注册到内核态struct eventpoll里面，所以epoll fd是用户态和内核态struct eventpoll的桥梁。&lt;/li&gt;
&lt;li&gt;有了上面的struct eventpoll，驱动只要把激发的事件放到eventpoll里面的事件就绪队列就可以了，然后唤醒进程后，检查就绪队列是否有事件，如果有直接把激发的事件copy到用户态的events里面即可。不用向select函数那样轮询每个监控的fd了。&lt;/li&gt;
&lt;li&gt;同时内核中对于每个fd形成一个结构体struct epitem，用红黑树来管理，这样保证了插入和查找的效率。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;struct eventpoll结构
&lt;pre&gt;&lt;code&gt;
struct eventpoll {
    /&lt;em&gt; Protect the access to this structure &lt;/em&gt;/
    spinlock_t lock;
    /&lt;em&gt;
     * This mutex is used to ensure that files are not removed
     * while epoll is using them. This is held during the event
     * collection loop, the file cleanup path, the epoll file exit
     * code and the ctl operations.
     &lt;/em&gt;/
    struct mutex mtx;
    /&lt;em&gt; Wait queue used by sys_epoll_wait() &lt;/em&gt;/
    //阻塞在epoll_wait函数的阻塞队列，当添加通过epoll_ctl添加事件后，poll函数返回了触发的事件，那么会直接通过这个wq唤醒epoll_wait进程，或者中断处理函数唤醒epoll_wait进程
    wait_queue_head_t wq; &lt;br /&gt;
    /&lt;em&gt; Wait queue used by file-&amp;gt;poll() &lt;/em&gt;/
    //调用epoll fd poll函数的进程的阻塞队列，关心的是是否有注册事件，当有注册事件的时候会唤醒相关进程
    wait_queue_head_t poll_wait;
    /&lt;em&gt; List of ready file descriptors &lt;/em&gt;/
    //就绪事件队列，中断会入队事件
    struct list_head rdllist; 
    /&lt;em&gt; RB tree root used to store monitored fd structs &lt;/em&gt;/
    //管理fd的红黑树
    struct rb_root rbr;
    /&lt;em&gt;
     * This is a single linked list that chains all the "struct epitem" that
     * happened while transferring ready events to userspace w/out
     * holding -&amp;gt;lock.
     &lt;/em&gt;/
    struct epitem &lt;em&gt;ovflist;
    /&lt;/em&gt; The user that created the eventpoll descriptor &lt;em&gt;/
    struct user_struct &lt;/em&gt;user;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;epoll_create函数创建struct file，struct eventpoll，把eventpoll放到file的private_data中，以后使用eventpoll的时候，直接通过fd找到file，再通过private_data找到。&lt;/p&gt;
&lt;p&gt;epoll_ctl注册事件，主要流程设置阻塞队列，调用fd的poll函数，监测是否有事件发生，如果已经有事件发生，那么把事件放到rdllist中，同时唤醒eventpoll-&amp;gt;wq中的进程。&lt;/p&gt;
&lt;p&gt;核心代码：
&lt;pre&gt;&lt;code&gt;
    epi = ep_find(ep, tfile, fd);//通过红黑树来查找fd对应的epitem
    error = -EINVAL;
    switch (op) {
    case EPOLL_CTL_ADD:
        if (!epi) {
            epds.events |= POLLERR | POLLHUP;
            error = ep_insert(ep, &amp;amp;epds, tfile, fd); //添加关注事件
        } else
            error = -EEXIST;
        break;
    case EPOLL_CTL_DEL:
        if (epi)
            error = ep_remove(ep, epi);
        else
            error = -ENOENT;
        break;
    case EPOLL_CTL_MOD:
        if (epi) {
            epds.events |= POLLERR | POLLHUP;
            error = ep_modify(ep, epi, &amp;amp;epds);
        } else
            error = -ENOENT;
        break;
    }
    mutex_unlock(&amp;amp;ep-&amp;gt;mtx);&lt;/p&gt;
&lt;p&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;关注添加关注事件函数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
      //设置poll wait函数，设置wakeup回调函数
     init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc);

    /*
     * Attach the item to the poll hooks and get current event bits.
     * We can safely use the file* here because its usage count has
     * been increased by the caller of this function. Note that after
     * this operation completes, the poll callback can start hitting
     * the new item.
     */
    //调用tcp_poll函数，首先回调poll_wait函数，设置阻塞队列在socket的wait queue上
    revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;poll wait回调函数是ep_ptable_queue_proc&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
//whead是struct sock中的wait queue
static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead,
                 poll_table *pt)
{
    struct epitem *epi = ep_item_from_epqueue(pt);
    struct eppoll_entry *pwq;
     //分配wait entry
    if (epi-&gt;nwait &gt;= 0 &amp;&amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) {
        //设置wakeup函数
        init_waitqueue_func_entry(&amp;pwq-&gt;wait, ep_poll_callback);
        pwq-&gt;whead = whead;
        pwq-&gt;base = epi;
        //加入等待队列
        add_wait_queue(whead, &amp;pwq-&gt;wait);
        list_add_tail(&amp;pwq-&gt;llink, &amp;epi-&gt;pwqlist);
        epi-&gt;nwait++;
    } else {
        /* We have to signal that an error occurred */
        epi-&gt;nwait = -1;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ep_epoll_callback函数是中断回调函数，和select函数调用机制相同&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static int ep_poll_callback(wait_queue_t *wait, unsigned mode, int sync, void *key)
{
    int pwake = 0;
    unsigned long flags;
    struct epitem *epi = ep_item_from_wait(wait);
    struct eventpoll *ep = epi-&gt;ep;

    spin_lock_irqsave(&amp;ep-&gt;lock, flags);

    /*
     * If the event mask does not contain any poll(2) event, we consider the
     * descriptor to be disabled. This condition is likely the effect of the
     * EPOLLONESHOT bit that disables the descriptor when an event is received,
     * until the next EPOLL_CTL_MOD will be issued.
     */
     //如果设置了EPOLLONESHOT，那么只能触发一次事件
    if (!(epi-&gt;event.events &amp; ~EP_PRIVATE_BITS))
        goto out_unlock;

    /*
     * Check the events coming with the callback. At this stage, not
     * every device reports the events in the "key" parameter of the
     * callback. We need to be able to handle both cases here, hence the
     * test for "key" != NULL before the event match test.
     */
    //如果触发了事件，如果和注册的事件有交集，就继续加入rdllist，否则退出
    if (key &amp;&amp; !((unsigned long) key &amp; epi-&gt;event.events))
        goto out_unlock;

    /*
     * If we are transferring events to userspace, we can hold no locks
     * (because we're accessing user memory, and because of linux f_op-&gt;poll()
     * semantics). All the events that happen during that period of time are
     * chained in ep-&gt;ovflist and requeued later on.
     */
    //在最后copy事件到用户空间的时候会占用rdllist，这时把事件先放到ovflist中
    if (unlikely(ep-&gt;ovflist != EP_UNACTIVE_PTR)) {
        if (epi-&gt;next == EP_UNACTIVE_PTR) {
            epi-&gt;next = ep-&gt;ovflist;
            ep-&gt;ovflist = epi;
        }
        goto out_unlock;
    }
    //把事件加入rdllist中，一个fd一次
    /* If this file is already in the ready list we exit soon */
    if (!ep_is_linked(&amp;epi-&gt;rdllink))
        list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist);

    /*
     * Wake up ( if active ) both the eventpoll wait list and the -&gt;poll()
     * wait list.
     */
    //唤醒epoll_wait中的进程
    if (waitqueue_active(&amp;ep-&gt;wq))
        wake_up_locked(&amp;ep-&gt;wq);

    if (waitqueue_active(&amp;ep-&gt;poll_wait))
        pwake++;

out_unlock:
    spin_unlock_irqrestore(&amp;ep-&gt;lock, flags);

    /* We have to call this outside the lock */
    if (pwake)
        ep_poll_safewake(&amp;ep-&gt;poll_wait);

    return 1;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上需要注意的是，当epoll_wait进程正在处理rdllist的时候（把事件copy到用户态的变量），激发的事件会暂时放在ovflist，在说下epoll_wait的流程&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
fetch_events:
    spin_lock_irqsave(&amp;ep-&gt;lock, flags);

    if (!ep_events_available(ep)) {
        /*
         * We don't have any available event to return to the caller.
         * We need to sleep here, and we will be wake up by
         * ep_poll_callback() when events will become available.
         */
        init_waitqueue_entry(&amp;wait, current);  //初始化wait queue
        __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); //加入wait queue,中断后满足条件，会唤醒这个进程

        for (;;) {
            /*
             * We don't want to sleep if the ep_poll_callback() sends us
             * a wakeup in between. That's why we set the task state
             * to TASK_INTERRUPTIBLE before doing the checks.
             */
            set_current_state(TASK_INTERRUPTIBLE);
            if (ep_events_available(ep) || timed_out) //检查eventpoll的rdllist是否有激发的事件或者有事件暂时放在ovflist
                break;
            if (signal_pending(current)) { //如果有信号，那么也退出
                res = -EINTR;
                break;
            }

            spin_unlock_irqrestore(&amp;ep-&gt;lock, flags);
            if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) //进程休眠
                timed_out = 1;

            spin_lock_irqsave(&amp;ep-&gt;lock, flags);
        }
        __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); //已经有事件了，去掉阻塞队列

        set_current_state(TASK_RUNNING);
    }
check_events:
    /* Is it worth to try to dig for events ? */
    eavail = ep_events_available(ep); //是否有事件

    spin_unlock_irqrestore(&amp;ep-&gt;lock, flags);

    /*
     * Try to transfer events to user space. In case we get 0 events and
     * there's still timeout left over, we go trying again in search of
     * more luck.
     */
     //把事件复制到用户态的events
    if (!res &amp;&amp; eavail &amp;&amp;
        !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; !timed_out)
        goto fetch_events;

    return res;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终的收尾工作是ep_send_events，把rdllist中的事件copy到events里面，最终是函数ep_send_events_proc
完成这个工作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
for (eventcnt = 0, uevent = esed-&gt;events;
         !list_empty(head) &amp;&amp; eventcnt &lt; esed-&gt;maxevents;) {
        epi = list_first_entry(head, struct epitem, rdllink);

        list_del_init(&amp;epi-&gt;rdllink);
        //检查事件，wait是NULL，不会设置阻塞队列
        revents = epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, NULL) &amp;
            epi-&gt;event.events;

        /*
         * If the event mask intersect the caller-requested one,
         * deliver the event to userspace. Again, ep_scan_ready_list()
         * is holding "mtx", so no operations coming from userspace
         * can change the item.
         */
        if (revents) {
        //把事件放入用户态变量events
            if (__put_user(revents, &amp;uevent-&gt;events) ||
                __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) {
                list_add(&amp;epi-&gt;rdllink, head);
                return eventcnt ? eventcnt : -EFAULT;
            }
            eventcnt++;
            uevent++;
            if (epi-&gt;event.events &amp; EPOLLONESHOT)
                epi-&gt;event.events &amp;= EP_PRIVATE_BITS;
            else if (!(epi-&gt;event.events &amp; EPOLLET)) {
              //水平模式
                /*
                 * If this file has been added with Level
                 * Trigger mode, we need to insert back inside
                 * the ready list, so that the next call to
                 * epoll_wait() will check again the events
                 * availability. At this point, no one can insert
                 * into ep-&gt;rdllist besides us. The epoll_ctl()
                 * callers are locked out by
                 * ep_scan_ready_list() holding "mtx" and the
                 * poll callback will queue them in ep-&gt;ovflist.
                 */
                list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist);
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后说下epoll的水平触发和边沿触发模式&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;水平触发：每次触发事件后，无论用户态进程如何用read write处理数据，都会轮询调用fd的poll函数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;边沿触发：在中断处理函数处理后，发现事件，才会触发事件，其他时间不会主动轮询poll函数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以说select函数都是水平触发，调用select函数都是会轮询每个监控fd的poll函数，看是否有事件发生。所以对于用户态进程read write函数，如何处理数据，都无关，即便read取不干净buf中的数据，下次select函数轮询fd的poll函数的时候还会触发事件。&lt;/p&gt;
&lt;p&gt;epoll函数的水平触发，epoll函数的本意不是轮询fd的poll函数，假如中断函数唤醒了epoll_wait进程，把事件copy到了用户态，但是用户态进程，以read为例子，没有拿干净buf中的数据，那么如果之后没有数据到达，那么也就触发不了中断，也就触发不了事件，那么buf中剩余的数据是取不出来的。所以epoll函数默认情况下还是会把当前事件再次放到rdllist中，以便轮询事件。&lt;/p&gt;
&lt;p&gt;epoll函数的边缘触发和水平触发的不同之处在于，epoll函数处理完当前事件后，不会把事件再次加入到rdllist中，也就是不会轮询fd的poll函数，那么这种情况下要求，用户态进程调用read函数把buf中的数据全部copy到用户态，write函数要求把buf写满。也就是说read函数需要不停的read，直到read出来的count小于buf的大小。不停的write出去的数据直到write出去的count小于buf的大小。&lt;/p&gt;
&lt;p&gt;从上面的代码可以看出，确实水平模式事件最后还是会再次加入rdllist中，所以如果epoll使用水平模式第一次触发事件的效率比select函数要高很多，因为中断把事件加入到了rdllist中，并没有轮询其他没有事件的fd的poll函数。后面会把epi加入到rdllist中做轮询，如果在socket未有新事件到达的情况下，一次read write未能处理干净数据的话，epoll会多次轮询，这会导致效率低下。处理干净数据后就不会再次加入到rdllist中了。所以水平模式下的epoll在用户态进程一次处理不完数据的情况下，会导致短暂的轮询，处理完成后解除轮询，效率会有比较大的影响。&lt;/p&gt;
&lt;p&gt;再者边缘模式的epoll，不存在轮询的现象，效率自然很高。但是要求read和write函数对buf处理需要彻底。这对于用户态来说，如何防止其他的连接上的数据不被饿死，代码就会更加复杂一些。&lt;/p&gt;</summary><category term="socket"></category></entry><entry><title>select函数原理分析</title><link href="/selecthan-shu-yuan-li-fen-xi.html" rel="alternate"></link><updated>2014-05-19T16:09:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-05-19:selecthan-shu-yuan-li-fen-xi.html</id><summary type="html">&lt;h1&gt;select函数原理分析&lt;/h1&gt;
&lt;p&gt;select函数大体原理：函数首先会递归每个文件描述符检查事件，如果没有相关的事件，那么就把当前进程添加到wait_queue中，然后改变当前进程的状态，使得进程不会得到时间片，从而使进程休眠；当设备中断，调用相关的驱动的方法，这时会检查wait_queue,然后唤醒相关的进程，这样会导致select进程继续执行，从新检查文件描述符的状态，这时至少有一个事件被激发，这样select函数就会返回了。select函数会顺序检查每个文件描述符的状态，当文件描述符数量十分巨大的情况下，会导致select函数的效率下降。&lt;/p&gt;
&lt;p&gt;select的核心函数是do_select函数，代码我就不copy了，说下里面必要重要的wait_queue的相关操作，初始化函数是&lt;code&gt;poll_initwait&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
void poll_initwait(struct poll_wqueues *pwq)
{
    init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait); //设置wait的时候的处理函数，在需要进程需要休眠的时候调用这个函数
    pwq-&gt;polling_task = current; //设置休眠的进程
    pwq-&gt;triggered = 0;
    pwq-&gt;error = 0;
    pwq-&gt;table = NULL; //初始化为null，后面有自己分配的地方
    pwq-&gt;inline_index = 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;do_select&lt;/code&gt;函数第一次会检查一下文件描述符的状态，同时设置好wait_queue触发的状态。&lt;/p&gt;
&lt;p&gt;file_operations的poll函数是检查一下文件是否有满足的状态，在调用poll函数之前，先设置poll关心的key&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
  f_op = file-&gt;f_op;
  mask = DEFAULT_POLLMASK;
  if (f_op &amp;&amp; f_op-&gt;poll) {
    wait_key_set(wait, in, out, bit);
    mask = (*f_op-&gt;poll)(file, wait);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;wait_key_set&lt;/code&gt;就是设置poll关心的key&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static inline void wait_key_set(poll_table *wait, unsigned long in,
                unsigned long out, unsigned long bit)
{
    if (wait) {
        wait-&gt;key = POLLEX_SET; //无论设置什么key，都需要关心exception状态
        if (in &amp; bit)
            wait-&gt;key |= POLLIN_SET;  //设置读事件的key
        if (out &amp; bit)
            wait-&gt;key |= POLLOUT_SET; //设置写事件的key
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;f_op-&amp;gt;poll&lt;/code&gt;，考虑网络连接fd，tcp连接，对应&lt;code&gt;tcp_poll&lt;/code&gt;函数，这个函数首先设置wait_queue，然后检查socket状态。首先看下设置wait_queue的函数&lt;code&gt;sock_poll_wait&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static inline void sock_poll_wait(struct file *filp,
        wait_queue_head_t *wait_address, poll_table *p)
{
    if (p &amp;&amp; wait_address) { //这里wait_address是struct sock中的sk_wq的wait_queue_head_t，可以看出个大概，就是把poll_table中的进程加入到sk_wq的wait_queue中，然后中断处理函数，会找到sock中的wait head，挨个唤醒进程
        poll_wait(filp, wait_address, p);
        /*
         * We need to be sure we are in sync with the
         * socket flags modification.
         *
         * This memory barrier is paired in the wq_has_sleeper.
        */
        smp_mb();
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;poll_wait函数调用的就是poll_table中的func函数&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static void __pollwait(struct file *filp, wait_queue_head_t *wait_address,
                poll_table *p)
{
    struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt);
    struct poll_table_entry *entry = poll_get_entry(pwq);  //获得entry
    if (!entry)
        return;
    get_file(filp);
    entry-&gt;filp = filp; 
    entry-&gt;wait_address = wait_address;
    entry-&gt;key = p-&gt;key; //设置关心的key，根据key来唤醒进程
    init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake); //设置唤醒回调函数
    entry-&gt;wait.private = pwq;
    add_wait_queue(wait_address, &amp;entry-&gt;wait);//加入到sock的wait队列中
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在创建&lt;code&gt;struct sock&lt;/code&gt;的时候，函数&lt;code&gt;sock_init_data&lt;/code&gt;设置了几个回调函数&lt;/p&gt;
&lt;p&gt;net/core/sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    sk-&gt;sk_state_change =   sock_def_wakeup; //连接状态变化
    sk-&gt;sk_data_ready   =   sock_def_readable; // socket有可读数据
    sk-&gt;sk_write_space  =   sock_def_write_space; //socket上可以写入数据
    sk-&gt;sk_error_report =   sock_def_error_report; //socket上有错误
    sk-&gt;sk_destruct     =   sock_def_destruct;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些回调函数都是底层网络驱动通过中断，先把数据提交到网络层，然后提交到传输层，最后调用回调函数来唤醒休眠的进程。具体的回调过程不是这个主题的重点，先不考虑。&lt;/p&gt;
&lt;p&gt;看下sock_def_readable函数的实现&lt;/p&gt;
&lt;p&gt;net/core/sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static void sock_def_readable(struct sock *sk, int len)
{
    struct socket_wq *wq;

    rcu_read_lock();
    wq = rcu_dereference(sk-&gt;sk_wq); //获得等待队列
    if (wq_has_sleeper(wq))
        wake_up_interruptible_sync_poll(&amp;wq-&gt;wait, POLLIN | POLLPRI |
                        POLLRDNORM | POLLRDBAND); //最后的flag匹配entry-&gt;key
    sk_wake_async(sk, SOCK_WAKE_WAITD, POLL_IN); //异步io，发送信号
    rcu_read_unlock();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终wake_up_interruptible_sync_poll函数最终会调用到__wake_up_common&lt;/p&gt;
&lt;p&gt;kernel/sched.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
tatic void __wake_up_common(wait_queue_head_t *q, unsigned int mode,
            int nr_exclusive, int wake_flags, void *key)
{
    wait_queue_t *curr, *next;
    //递归每一个挂在sock等待队列中的每一个元素
    list_for_each_entry_safe(curr, next, &amp;q-&gt;task_list, task_list) {
        unsigned flags = curr-&gt;flags;
        //调用wakeup回调函数
        if (curr-&gt;func(curr, mode, wake_flags, key) &amp;&amp;
                (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive)
            break;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里func是之前注册的回调函数poll_wake函数&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
static int pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key)
{
    struct poll_table_entry *entry;

    entry = container_of(wait, struct poll_table_entry, wait);
    //匹配key，如果匹配才唤醒进程，否则退出
    if (key &amp;&amp; !((unsigned long)key &amp; entry-&gt;key))
        return 0;
    return __pollwake(wait, mode, sync, key);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tcp_poll函数中设置完wait queue后，会首先检查一下socket的状态，检查是否有相关的事件发生，对于listening状态的socket，只要判断accept队列是否有连接即可，如果不为空，那么触发读相关事件&lt;/p&gt;
&lt;p&gt;首先看下触发读写状态的条件&lt;/p&gt;
&lt;p&gt;fs/select.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
//触发读事件
#define POLLIN_SET (POLLRDNORM | POLLRDBAND | POLLIN | POLLHUP | POLLERR)
//触发写事件
#define POLLOUT_SET (POLLWRBAND | POLLWRNORM | POLLOUT | POLLERR)
//触发异常事件
#define POLLEX_SET (POLLPRI)

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;
static inline unsigned int inet_csk_listen_poll(const struct sock *sk)
{
    return !reqsk_queue_empty(&amp;inet_csk(sk)-&gt;icsk_accept_queue) ?
            (POLLIN | POLLRDNORM) : 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果不是listening状态的socket，那么需要判断相关的相关参数
&lt;pre&gt;&lt;code&gt;
    //关闭状态，触发读事件
    if (sk-&amp;gt;sk_shutdown == SHUTDOWN_MASK || sk-&amp;gt;sk_state == TCP_CLOSE)
        mask |= POLLHUP;
    //读关闭，触发读事件
    if (sk-&amp;gt;sk_shutdown &amp;amp; RCV_SHUTDOWN)
        mask |= POLLIN | POLLRDNORM | POLLRDHUP;
    //如果当前socket状态不是sync sent或者sync recv
    if ((1 &amp;lt;&amp;lt; sk-&amp;gt;sk_state) &amp;amp; ~(TCPF_SYN_SENT | TCPF_SYN_RECV)) {
        //获得读水位
        int target = sock_rcvlowat(sk, 0, INT_MAX);
        if (tp-&amp;gt;urg_seq == tp-&amp;gt;copied_seq &amp;amp;&amp;amp;
            !sock_flag(sk, SOCK_URGINLINE) &amp;amp;&amp;amp;
            tp-&amp;gt;urg_data)
            target++;
            //如果有数据超过了水位线,触发读事件
        if (tp-&amp;gt;rcv_nxt - tp-&amp;gt;copied_seq &amp;gt;= target)
            mask |= POLLIN | POLLRDNORM;
        //如果不是写半关闭
        if (!(sk-&amp;gt;sk_shutdown &amp;amp; SEND_SHUTDOWN)) {
            //如果有写的空间，触发写事件
            if (sk_stream_wspace(sk) &amp;gt;= sk_stream_min_wspace(sk)) {
                mask |= POLLOUT | POLLWRNORM;
            } else {&lt;br /&gt;
                set_bit(SOCK_ASYNC_NOSPACE,
                    &amp;amp;sk-&amp;gt;sk_socket-&amp;gt;flags);
                set_bit(SOCK_NOSPACE, &amp;amp;sk-&amp;gt;sk_socket-&amp;gt;flags);
                if (sk_stream_wspace(sk) &amp;gt;= sk_stream_min_wspace(sk))
                    mask |= POLLOUT | POLLWRNORM;
            }
        } else
            //写半关闭触发写事件
            mask |= POLLOUT | POLLWRNORM;
        if (tp-&amp;gt;urg_data &amp;amp; TCP_URG_VALID)
            mask |= POLLPRI;
    }
    /&lt;em&gt; This barrier is coupled with smp_wmb() in tcp_reset() &lt;/em&gt;/
    smp_rmb();
    if (sk-&amp;gt;sk_err)
        mask |= POLLERR;
    return mask;
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;</summary><category term="socket"></category></entry><entry><title>socket绑定端口流程</title><link href="/socketbang-ding-duan-kou-liu-cheng.html" rel="alternate"></link><updated>2014-05-13T11:33:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-05-13:socketbang-ding-duan-kou-liu-cheng.html</id><summary type="html">&lt;h1&gt;socket绑定端口过程&lt;/h1&gt;
&lt;p&gt;绑定端口分为2种，一种是指定端口号，然后内核去判断这个端口号是否可用，另一种是填端口号为0，内核去从端口号范围内选择一个端口。具体过程是在inet_csk_get_port函数中，本文中内核版本2.6.39.14&lt;/p&gt;
&lt;p&gt;先说明一个非常重要的函数inet_csk_bind_conflict，在bind hash找到相同的端口，那么会根据reuseaddr，reuseport和tcp状态来决定这个端口是否是可用。
&lt;pre&gt;&lt;code&gt;
inet_get_local_port_range(&amp;amp;low, &amp;amp;high); //首先确定端口号范围
        remaining = (high - low) + 1;    //表示可以尝试端口号的机会
        smallest_rover = rover = net_random() % remaining + low;&lt;br /&gt;
        //从端口号范围内随机选择一个端口号为起点，开始遍历选择
        smallest_size = -1;  //如果没有可用的端口号，会选择被reuse最少的端口号
        do {
            if (inet_is_reserved_local_port(rover))//如果这个随机端口号是保留的，那么不考虑
                goto next_nolock;
                //这里bhash是绑定端口号的hash结构，net是网络命名空间，暂时不考虑，rover是端口参考值，这里计算参考值的hash index，struct inet_bind_bucket是hash的元素，这里取hash位置的双链表的head指针
            head = &amp;amp;hashinfo-&amp;gt;bhash[inet_bhashfn(net, rover,
                    hashinfo-&amp;gt;bhash_size)]; 
            spin_lock(&amp;amp;head-&amp;gt;lock);
            //遍历双链表，寻找rover的记录，如果没有找到，那就是可用的端口，如果找到了，判断状态来决定端口是否可用
            inet_bind_bucket_for_each(tb, node, &amp;amp;head-&amp;gt;chain)
                if (net_eq(ib_net(tb), net) &amp;amp;&amp;amp; tb-&amp;gt;port == rover) {
                //如果已经绑定的socket设置了reuse，同时当前socket设置了reuse，当前socket状态不是listen状态，同时这个端口的可重用的阈值是最小的，或重用阈值为-1（初始阈值），目的是找到端口重用度最小的阈值的那个端口
                    if (tb-&amp;gt;fastreuse &amp;gt; 0 &amp;amp;&amp;amp;
                        sk-&amp;gt;sk_reuse &amp;amp;&amp;amp;
                        sk-&amp;gt;sk_state != TCP_LISTEN &amp;amp;&amp;amp;
                        (tb-&amp;gt;num_owners &amp;lt; smallest_size || smallest_size == -1)) {
                        //更新阈值
                        smallest_size = tb-&amp;gt;num_owners;
                        smallest_rover = rover;//保存这个最小阈值的端口
                        //如果端口bind hash已经有了足够多的绑定端口，那么当前端口就是备选。避免了遍历数量很多的bind hash，这个应该是内核中的一个小小的优化吧。以前的版本没看过
                        if (atomic_read(&amp;amp;hashinfo-&amp;gt;bsockets) &amp;gt; (high - low) + 1) {
                            spin_unlock(&amp;amp;head-&amp;gt;lock);
                            snum = smallest_rover;
                            goto have_snum;
                        }
                    }
                    goto next;
                }
            //到了这里表示端口已经找到并且这个端口
            break;
        next:
            spin_unlock(&amp;amp;head-&amp;gt;lock);
        next_nolock:
            if (++rover &amp;gt; high)
                rover = low;
        } while (--remaining &amp;gt; 0);
         //已经遍历了一遍了，如果阈值（smallest_rover）还是-1，那么证明所有端口都被占用，同时都为设置reuse，那么只能失败了，否则使用reuse占用最少的端口，这种情况也是端口都被占用，但是有一些是reuse的，并且当前的端口是reuse的。
        ret = 1;
        if (remaining &amp;lt;= 0) {
            if (smallest_size != -1) {
                snum = smallest_rover;
                goto have_snum;
            }
            goto fail;
        }
        /&lt;em&gt; OK, here is the one we will use.  HEAD is
         * non-NULL and we hold it's mutex.
         &lt;/em&gt;/
        snum = rover;
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;1.未指定端口号&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
        //首先确定端口号范围
        inet_get_local_port_range(net, &amp;low, &amp;high);
        //表示可以尝试端口号的机会
        remaining = (high - low) + 1;
        //从端口号范围内随机选择一个端口号为起点，开始遍历选择
        smallest_rover = rover = prandom_u32() % remaining + low;
        //如果没有可用的端口号，会选择被reuse最少的端口号
        smallest_size = -1;
        do {
            //如果这个随机端口号是保留的，那么不考虑
            if (inet_is_reserved_local_port(rover))
                goto next_nolock;
            //这里bhash是绑定端口号的hash结构，net是网络命名空间，暂时不考虑，rover是端口参考值，这里计算参考值的hash index，struct inet_bind_bucket是hash的元素，这里取hash位置的双链表的head指针
            head = &amp;hashinfo-&gt;bhash[inet_bhashfn(net, rover,
                    hashinfo-&gt;bhash_size)];
            spin_lock(&amp;head-&gt;lock);
            //遍历双链表，寻找rover的记录，如果没有找到，那就是可用的端口，如果找到了，判断状态来决定端口是否可用
            inet_bind_bucket_for_each(tb, &amp;head-&gt;chain)
                //如果已经绑定的端口在同一命名空间中，端口是当前随机端口
                if (net_eq(ib_net(tb), net) &amp;&amp; tb-&gt;port == rover) {
                    //如果tb和sk同时设置了reuse，sk状态不是listen或者reuseport，同时这个端口的重用阈值未设置，或者小于阈值，那么这个端口作为备选
                    if (((tb-&gt;fastreuse &gt; 0 &amp;&amp; sk-&gt;sk_reuse &amp;&amp; sk-&gt;sk_state != TCP_LISTEN)||(tb-&gt;fastreuseport &gt; 0 &amp;&amp;sk-&gt;sk_reuseport &amp;&amp;uid_eq(tb-&gt;fastuid, uid))) &amp;&amp;
                        (tb-&gt;num_owners &lt; smallest_size || smallest_size == -1)) {
                        smallest_size = tb-&gt;num_owners;
                        smallest_rover = rover;
                        //如果hashinfo中的bind到了一定的数量，就挑选当前重用度最低的端口
                        if (atomic_read(&amp;hashinfo-&gt;bsockets) &gt; (high - low) + 1 &amp;&amp;
                            !inet_csk(sk)-&gt;icsk_af_ops-&gt;bind_conflict(sk, tb, false)) {
                            snum = smallest_rover;
                            goto tb_found;
                        }
                    }
                    if (!inet_csk(sk)-&gt;icsk_af_ops-&gt;bind_conflict(sk, tb, false)) {
                        snum = rover;
                        goto tb_found;
                    }
                    goto next;
                }
            //找到了未绑定的端口就退出
            break;
        next:
            spin_unlock(&amp;head-&gt;lock);
        next_nolock:
            if (++rover &gt; high)
                rover = low;
        } while (--remaining &gt; 0);

        /* Exhausted local port range during search?  It is not
         * possible for us to be holding one of the bind hash
         * locks if this test triggers, because if 'remaining'
         * drops to zero, we broke out of the do/while loop at
         * the top level, not from the 'break;' statement.
         */
        ret = 1;
        if (remaining &lt;= 0) {
            if (smallest_size != -1) {
                snum = smallest_rover;
                goto have_snum;
            }
            goto fail;
        }
        /* OK, here is the one we will use.  HEAD is
         * non-NULL and we hold it's mutex.
         */
        snum = rover;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.指定了端口号&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
//如果指定了端口号
 else {
have_snum:
        head = &amp;hashinfo-&gt;bhash[inet_bhashfn(net, snum,
                hashinfo-&gt;bhash_size)];
        spin_lock(&amp;head-&gt;lock);
        //如果在同一个命名空间，端口号相同就去tb_found,否则就是去tb_not_found
        inet_bind_bucket_for_each(tb, node, &amp;head-&gt;chain)
            if (net_eq(ib_net(tb), net) &amp;&amp; tb-&gt;port == snum)
                goto tb_found;
    }
    tb = NULL;
    goto tb_not_found;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码中可以看出，如果未指定端口，如果从bind hash找到了未使用的端口就使用，否则表示所有端口都已经使用，同时已经选择除了重用度最小的端口作为备选，这种情况会到tb_found。再有如果指定了端口，同时这个端口已经被占用，也会到tb_found。&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
tb_found:
    //如果reuse的使用者不为空
    if (!hlist_empty(&amp;tb-&gt;owners)) {
        //如果占用端口的reuse为1，同时当前reuse也为1，socket状态不是listen，
        smallest_size为-1表示指定了端口，端口被占用。未指定的端口也可能到这里，就是bind hash已经超过了(high - low) + 1
        if (tb-&gt;fastreuse &gt; 0 &amp;&amp;
            sk-&gt;sk_reuse &amp;&amp; sk-&gt;sk_state != TCP_LISTEN &amp;&amp;
            smallest_size == -1) {
            goto success;
        } else {
            //这里要调用bind_conflict函数，如果失败，socket是reuse，attempts&gt;0,表示还有机会选择其他的端口
            ret = 1;
            if (inet_csk(sk)-&gt;icsk_af_ops-&gt;bind_conflict(sk, tb)) {
                if (sk-&gt;sk_reuse &amp;&amp; sk-&gt;sk_state != TCP_LISTEN &amp;&amp;
                    smallest_size != -1 &amp;&amp; --attempts &gt;= 0) {
                    spin_unlock(&amp;head-&gt;lock);
                    goto again;
                }
                goto fail_unlock;
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bind_conflict函数的实现&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
int inet_csk_bind_conflict(const struct sock *sk,
               const struct inet_bind_bucket *tb)
{
    struct sock *sk2;
    struct hlist_node *node;
    int reuse = sk-&gt;sk_reuse;

    /*
     * Unlike other sk lookup places we do not check
     * for sk_net here, since _all_ the socks listed
     * in tb-&gt;owners list belong to the same net - the
     * one this bucket belongs to.
     */
    //对于reuse的端口进行便利
    //不使用同一个接收地址的socket可以共用端口号，绑定在不同的网络设备接口上的socket可以共用端口号，或者两个socket都表示自己可以被重用，并且还不在TCP_LISTEN状态，则可以重用端口号。
    sk_for_each_bound(sk2, node, &amp;tb-&gt;owners) {
        if (sk != sk2 &amp;&amp;
            !inet_v6_ipv6only(sk2) &amp;&amp;
            (!sk-&gt;sk_bound_dev_if ||
             !sk2-&gt;sk_bound_dev_if ||
             sk-&gt;sk_bound_dev_if == sk2-&gt;sk_bound_dev_if)) {
            if (!reuse || !sk2-&gt;sk_reuse ||
                sk2-&gt;sk_state == TCP_LISTEN) {
                const __be32 sk2_rcv_saddr = sk_rcv_saddr(sk2);
                if (!sk2_rcv_saddr || !sk_rcv_saddr(sk) ||
                    sk2_rcv_saddr == sk_rcv_saddr(sk))
                    break;
            }
        }
    }
    return node != NULL;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面的逻辑是如果这个端口不是重用端口，那么就在bind hash中创建记录&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
ret = 1;
    //如果在hash中有记录，那么tb一定是reuse的端口，否则在hash中创建记录
    if (!tb &amp;&amp; (tb = inet_bind_bucket_create(hashinfo-&gt;bind_bucket_cachep,
                    net, head, snum)) == NULL)
        goto fail_unlock;
    //如果这个端口没有重用过，新建立的端口
    if (hlist_empty(&amp;tb-&gt;owners)) {
        if (sk-&gt;sk_reuse &amp;&amp; sk-&gt;sk_state != TCP_LISTEN)
        //reuse置为1
            tb-&gt;fastreuse = 1;
        else
            tb-&gt;fastreuse = 0;//表示不能重用
    //这个暂时没有搞懂的逻辑
    } else if (tb-&gt;fastreuse &amp;&amp;
           (!sk-&gt;sk_reuse || sk-&gt;sk_state == TCP_LISTEN))
        tb-&gt;fastreuse = 0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后做收尾工作&lt;/p&gt;
&lt;p&gt;net/ipv4/inet_connection_sock.c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
void inet_bind_hash(struct sock *sk, struct inet_bind_bucket *tb,
            const unsigned short snum)
{
    struct inet_hashinfo *hashinfo = sk-&gt;sk_prot-&gt;h.hashinfo;

    atomic_inc(&amp;hashinfo-&gt;bsockets);

    inet_sk(sk)-&gt;inet_num = snum;
    sk_add_bind_node(sk, &amp;tb-&gt;owners);
    tb-&gt;num_owners++;
    inet_csk(sk)-&gt;icsk_bind_hash = tb;
}
&lt;/code&gt;&lt;/pre&gt;</summary><category term="socket"></category></entry><entry><title>socket创建流程2</title><link href="/socketchuang-jian-liu-cheng-2.html" rel="alternate"></link><updated>2014-05-09T15:14:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-05-09:socketchuang-jian-liu-cheng-2.html</id><summary type="html">&lt;h1&gt;socket创建流程2&lt;/h1&gt;
&lt;p&gt;linux内核创建socket时，会初始化&lt;code&gt;struct sock&lt;/code&gt;，后面针对net family的不通和protocol的不同，对&lt;code&gt;struct sock&lt;/code&gt;有多种扩展，主要的扩展图如下：&lt;/p&gt;</summary><category term="socket"></category></entry><entry><title>socket创建流程1</title><link href="/socketchuang-jian-liu-cheng-1.html" rel="alternate"></link><updated>2014-05-09T10:49:00+02:00</updated><author><name>djjsindy</name></author><id>tag:,2014-05-09:socketchuang-jian-liu-cheng-1.html</id><summary type="html">&lt;h1&gt;socket创建流程1&lt;/h1&gt;
&lt;p&gt;linux内核在系统初始化的过程中，会对支持的多个协议组进行初始化，例如ipv4，ipv6，unix域协议。这些协议的结构体通过&lt;code&gt;sock_register&lt;/code&gt;放在一个&lt;code&gt;net_families&lt;/code&gt;的数组中。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://lh5.googleusercontent.com/-fdHJThfthJ0/U2tXrsCfNjI/AAAAAAAAAPk/xtrusNqcVis/s1024/Screen%2520Shot%25202014-05-08%2520at%25206.07.45%2520PM.png" width="600"&gt;&lt;/p&gt;
&lt;p&gt;linux内核在初始化过程中，会调用inet_init函数，前半部分重要的代码：&lt;/p&gt;
&lt;p&gt;net/ipv4/af_inet.c&lt;/p&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;&lt;br /&gt;
    (void)sock_register(&amp;amp;inet_family_ops);  //该回调函数注册inet_family_ops
    #ifdef CONFIG_SYSCTL
    ip_static_sysctl_init();      &lt;br /&gt;
    #endif   //以下注册网络层到  &lt;br /&gt;
    if (inet_add_protocol(&amp;amp;icmp_protocol, IPPROTO_ICMP) &amp;lt; 0)
        printk(KERN_CRIT "inet_init: Cannot add ICMP protocol\n");
    if (inet_add_protocol(&amp;amp;udp_protocol, IPPROTO_UDP) &amp;lt; 0)
        printk(KERN_CRIT "inet_init: Cannot add UDP protocol\n");
    if (inet_add_protocol(&amp;amp;tcp_protocol, IPPROTO_TCP) &amp;lt; 0)
        printk(KERN_CRIT "inet_init: Cannot add TCP protocol\n");
    #ifdef CONFIG_IP_MULTICAST
    if (inet_add_protocol(&amp;amp;igmp_protocol, IPPROTO_IGMP) &amp;lt; 0)
        printk(KERN_CRIT "inet_init: Cannot add IGMP protocol\n");
    #endif
    /&lt;em&gt; Register the socket-side information for inet_create. &lt;/em&gt;/ 
    for (r = &amp;amp;inetsw[0]; r &amp;lt; &amp;amp;inetsw[SOCK_MAX]; ++r)
        INIT_LIST_HEAD(r);
    for (q = inetsw_array; q &amp;lt; &amp;amp;inetsw_array[INETSW_ARRAY_LEN]; ++q)
        inet_register_protosw(q);  //注册传输层协议结构体&lt;/p&gt;
&lt;p&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;上面的代码中&lt;code&gt;inetsw_array&lt;/code&gt;是一个表示传输层协议的结构体
net/ipv4/af_inet.c
&lt;pre&gt;&lt;code&gt;
static struct inet_protosw inetsw_array[] =
{
    {
        .type =       SOCK_STREAM,   //字节流
        .protocol =   IPPROTO_TCP, &lt;br /&gt;
        .prot =       &amp;amp;tcp_prot,     //tcp的一些回调函数
        .ops =        &amp;amp;inet_stream_ops,  //字节流模式的回调函数
        .no_check =   0,
        .flags =      INET_PROTOSW_PERMANENT |INET_PROTOSW_ICSK,
    },
    {
        .type =       SOCK_DGRAM,
        .protocol =   IPPROTO_UDP,
        .prot =       &amp;amp;udp_prot,
        .ops =        &amp;amp;inet_dgram_ops,
        .no_check =   UDP_CSUM_DEFAULT,
        .flags =      INET_PROTOSW_PERMANENT,
    },
    {
        .type =       SOCK_RAW,
        .protocol =   IPPROTO_IP,   /&lt;em&gt; wild card &lt;/em&gt;/
        .prot =       &amp;amp;raw_prot,
        .ops =        &amp;amp;inet_sockraw_ops,
        .no_check =   UDP_CSUM_DEFAULT,
        .flags =      INET_PROTOSW_REUSE,
    }
};
&lt;/pre&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所以对于对于经常写的代码&lt;code&gt;socket(AF_INET, SOCK_STREAM, 0);&lt;/code&gt;，创建socket结构，首先根据第一个参数&lt;code&gt;AF_INET&lt;/code&gt;，在&lt;code&gt;net_families&lt;/code&gt;数组中匹配到&lt;code&gt;inet_family_ops&lt;/code&gt;，再根据&lt;code&gt;inetsw_array&lt;/code&gt;数组中的type和protocol设置prot和ops指针，&lt;code&gt;inet_init&lt;/code&gt;后面的初始化暂时看不懂。&lt;/p&gt;
&lt;p&gt;net/socket.c
&lt;pre&gt;&lt;code&gt;
pf = rcu_dereference(net_families[family]); 
//根据family确定使用哪个family，AF_INET使用inet_family_ops
err = -EAFNOSUPPORT;
if (!pf)
    goto out_release;
if (!try_module_get(pf-&amp;gt;owner))
    goto out_release;
rcu_read_unlock();
err = pf-&amp;gt;create(net, sock, protocol, kern); //调用inet的create函数
if (err &amp;lt; 0)
    goto out_module_put;&lt;/p&gt;
&lt;p&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;net/ipv4/af_inet.c
&lt;pre&gt;&lt;code&gt;
//根据type和protocol从inetsw_array选择合适的inet_protosw
list_for_each_entry_rcu(answer, &amp;amp;inetsw[sock-&amp;gt;type], list) {
        err = 0;
        if (protocol == answer-&amp;gt;protocol) {
            if (protocol != IPPROTO_IP)
                break;
        } else {
            /&lt;em&gt; Check for the two wild cases. &lt;/em&gt;/
            if (IPPROTO_IP == protocol) {
                protocol = answer-&amp;gt;protocol;
                break;
            }
            if (IPPROTO_IP == answer-&amp;gt;protocol)
                break;
        }
        err = -EPROTONOSUPPORT;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;看下struct socket的结构&lt;/p&gt;
&lt;p&gt;&lt;img src="https://lh6.googleusercontent.com/-ntSul2-gNTc/U2w7Sm1rPMI/AAAAAAAAAQE/OeK6SvuhXmU/s800/Screen%2520Shot%25202014-05-09%2520at%252010.16.33%2520AM.png" width="500"&gt;&lt;/p&gt;
&lt;p&gt;可以看出struct socket的结构分为了2个部分，通过file连接底层驱动，sock记录tcp连接状态，proto_ops是各种操作函数的结构体，上面的代码选择出了protocol，那么对应到这图中，对struct socket中的proto_ops和sock_common中的skc_prot进行了赋值。这两个都是相关协议的回调函数接口。&lt;/p&gt;</summary><category term="socket"></category></entry></feed>